{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCL Thread Coarsening\n",
    "\n",
    "This notebook contains the experiments for Case Study B - using deep learning to predict thread coarsening factor for OpenCL kernels, without hand engineered features.\n",
    "\n",
    "## 1. Runtime Data\n",
    "\n",
    "We use author-provided runtime data from the PACT'14 paper that we compare against [1].\n",
    "\n",
    "> [1] Magni, A., Dubach, C., & Oâ€™Boyle, M. (2014). [Automatic Optimization of Thread-Coarsening for Graphics Processors](http://www.research.ed.ac.uk/portal/files/19958629/magni14pact.pdf). In PACT. ACM.\n",
    "\n",
    "The data consists of runtimes from 17 benchmarks accross 4 experimental platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "df = pd.read_csv(\"../data/case-study-b/pact-2014-runtimes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can derive the \"oracle\" thread coarsening factors, i.e. the thread coarsening factors which provided the lowest runtime on each of the four architectures, for each of the 17 benchmarks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracles = pd.read_csv(\"../data/case-study-b/pact-2014-oracles.csv\")\n",
    "oracles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive Models\n",
    "\n",
    "We define a base class for implementing predictive models for thread coarsening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from clgen import atomizer as clgen\n",
    "\n",
    "class ThreadCoarseningModel(object):\n",
    "    \"\"\"\n",
    "    A model for predicting OpenCL thread coarsening factors.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    __name__ : str\n",
    "        Model name\n",
    "    __basename__ : str\n",
    "        Shortened name, used for files\n",
    "    \"\"\"\n",
    "    __name__ = None\n",
    "    __basename__ = None\n",
    "\n",
    "    def init(self, seed: int) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "\n",
    "        Do whatever is required to setup a new thread coarsening model here.\n",
    "        This method is called prior to training and predicting.\n",
    "        This method may be omitted if no initial setup is required.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int\n",
    "            The seed value used to reproducible results. May be 'None',\n",
    "            indicating that no seed is to be used.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self, outpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Save model state.\n",
    "\n",
    "        This must capture all of the relevant state of the model. It is up\n",
    "        to implementing classes to determine how best to save the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        outpath : str\n",
    "            The path to save the model state to.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def restore(self, inpath: str) -> None:\n",
    "        \"\"\"\n",
    "        Load a trained model from file.\n",
    "\n",
    "        This is called in place of init() if a saved model file exists. It\n",
    "        must restore all of the required model state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inpath : str\n",
    "            The path to load the model from. This is the same path as\n",
    "            was passed to save() to create the file.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        \"\"\"\n",
    "        Train a model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cascading_features : np.array\n",
    "            An array of feature vectors of shape (n,7,7). Used for the cascading\n",
    "            model, there are 7 vectors of 7 features for each benchmark, one for\n",
    "            each coarsening factor.\n",
    "\n",
    "        cascading_y : np.array\n",
    "            An array of classification labels of shape(n,7). Used for the cascading\n",
    "            model.\n",
    "\n",
    "        sequences : np.array\n",
    "            An array of encoded source code sequences of shape (n,seq_length).\n",
    "\n",
    "        y_1hot : np.array\n",
    "            An array of optimal coarsening factors of shape (n,6), in 1-hot encoding.\n",
    "\n",
    "        verbose: bool, optional\n",
    "            Whether to print verbose status messages during training.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Make predictions for programs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cascading_features : np.array\n",
    "            An array of feature vectors of shape (n,7,7). Used for the cascading\n",
    "            model, there are 7 vectors of 7 features for each benchmark, one for\n",
    "            each coarsening factor.\n",
    "\n",
    "        sequences : np.array\n",
    "            An array of encoded source code sequences of shape (n,seq_length).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Predicted 'y' values (optimal thread coarsening factors) with shape (n,1).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define some utility code which we will use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfs = [1, 2, 4, 8, 16, 32]  # thread coarsening factors\n",
    "\n",
    "def get_onehot(df, platform):\n",
    "    hot = np.zeros((len(df), len(cfs)), dtype=np.int32)\n",
    "    for i, cf in enumerate(df[f\"cf_{platform}\"]):\n",
    "        hot[i][cfs.index(cf)] = 1\n",
    "\n",
    "    return hot\n",
    "\n",
    "\n",
    "def get_magni_features(df, oracles, platform):\n",
    "    \"\"\"\n",
    "    Assemble cascading data.\n",
    "    \"\"\"\n",
    "    X_cc, y_cc, = [], []\n",
    "    for kernel in sorted(set(df[\"kernel\"])):\n",
    "        _df = df[df[\"kernel\"] == kernel]\n",
    "\n",
    "        oracle_cf = int(oracles[oracles[\"kernel\"] == kernel][f\"cf_{platform}\"].values[0])\n",
    "\n",
    "        feature_vectors = np.asarray([\n",
    "            _df['PCA1'].values,\n",
    "            _df['PCA2'].values,\n",
    "            _df['PCA3'].values,\n",
    "            _df['PCA4'].values,\n",
    "            _df['PCA5'].values,\n",
    "            _df['PCA6'].values,\n",
    "            _df['PCA7'].values,\n",
    "        ]).T\n",
    "                \n",
    "        X_cc.append(feature_vectors)\n",
    "        y = []\n",
    "        cfs__ = []\n",
    "        for i, cf in enumerate(cfs[:len(feature_vectors)]):\n",
    "            y_ = 1 if cf < oracle_cf else 0\n",
    "            y.append(y_)\n",
    "        y_cc.append(y)\n",
    "    \n",
    "        assert len(feature_vectors) == len(y)\n",
    "        \n",
    "    assert len(X_cc) == len(y_cc) == 17\n",
    "    \n",
    "    return np.asarray(X_cc), np.asarray(y_cc)\n",
    "\n",
    "\n",
    "def encode_srcs(srcs):\n",
    "    \"\"\" encode and pad source code for learning \"\"\"\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    \n",
    "    seqs = [atomizer.atomize(src) for src in srcs]\n",
    "    pad_val = atomizer.vocab_size\n",
    "    encoded = np.array(pad_sequences(seqs, maxlen=1024, value=pad_val))\n",
    "    return np.vstack([np.expand_dims(x, axis=0) for x in encoded])\n",
    "\n",
    "\n",
    "def platform2str(platform):\n",
    "    if platform == \"Fermi\":\n",
    "        return \"NVIDIA GTX 480\"\n",
    "    elif platform == \"Kepler\":\n",
    "        return \"NVIDIA Tesla K20c\"\n",
    "    elif platform == \"Cypress\":\n",
    "        return \"AMD Radeon HD 5900\"\n",
    "    elif platform == \"Tahiti\":\n",
    "        return \"AMD Tahiti 7970\"\n",
    "    else:\n",
    "        raise LookupError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimental Methodology\n",
    "\n",
    "For reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source encoder (see the *'Language Model.ipynb'* notebook for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = '\\n'.join(pd.read_csv(\"../data/case-study-a/cgo17-amd.csv\")['src'].values)\n",
    "atomizer = clgen.GreedyAtomizer.from_text(srcs)\n",
    "atomizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from labm8 import fs\n",
    "\n",
    "def evaluate(model):\n",
    "    # report progress:\n",
    "    from progressbar import ProgressBar\n",
    "    progressbar = [0, ProgressBar(max_value=68)]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    X_seq = None  # defer sequence encoding (it's expensive)\n",
    "    \n",
    "    for i, platform in enumerate([\"Cypress\", \"Tahiti\", \"Fermi\", \"Kepler\"]):\n",
    "        platform_name = platform2str(platform)\n",
    "                \n",
    "        # load data\n",
    "        oracle_runtimes = np.array([float(x) for x in oracles[\"runtime_\" + platform]])\n",
    "        y = np.array([int(x) for x in oracles[\"cf_\" + platform]], dtype=np.int32)\n",
    "        y_1hot = get_onehot(oracles, platform)\n",
    "        X_cc, y_cc = get_magni_features(df, oracles, platform)\n",
    "        \n",
    "        # LOOCV\n",
    "        kf = KFold(n_splits=len(y), shuffle=False)\n",
    "    \n",
    "        for j, (train_index, test_index) in enumerate(kf.split(y)):\n",
    "            kernel = sorted(set(df[\"kernel\"]))[test_index[0]]\n",
    "\n",
    "            model_name = model.__name__\n",
    "            model_basename = model.__basename__\n",
    "            \n",
    "            model_path = f\"../data/case-study-b/models/{model_basename}-{platform}-{j}.model\"\n",
    "            predictions_path = f\"../data/case-study-b/predictions/{model_basename}-{platform}-{j}.result\"  \n",
    "\n",
    "            if fs.exists(predictions_path):\n",
    "                # load result from cache\n",
    "                with open(predictions_path, 'rb') as infile:\n",
    "                    p = pickle.load(infile)\n",
    "            else:\n",
    "                if fs.exists(model_path):\n",
    "                    # load a trained model from cache\n",
    "                    model.restore(model_path)\n",
    "                else:\n",
    "                    # encode source codes\n",
    "                    if X_seq is None:\n",
    "                        X_seq = encode_srcs(df[\"src\"].values)\n",
    "\n",
    "                    # create a new model and train it\n",
    "                    model.init(seed=seed)\n",
    "                    model.train(cascading_features=np.concatenate(X_cc[train_index]),\n",
    "                                cascading_y=np.concatenate(y_cc[train_index]),\n",
    "                                sequences=X_seq[train_index],\n",
    "                                verbose=True, # TODO\n",
    "                                y_1hot=y_1hot[train_index])\n",
    "\n",
    "                    # cache the model\n",
    "                    fs.mkdir(fs.dirname(model_path))\n",
    "                    model.save(model_path)\n",
    "\n",
    "                # make prediction\n",
    "                p = model.predict(cascading_features=X_cc[test_index[0]], sequences=X_seq[test_index])[0]\n",
    "                p = min(p, 2 ** (len(X_cc[test_index[0]]) - 1))\n",
    "                \n",
    "                # cache the prediction\n",
    "                fs.mkdir(fs.dirname(predictions_path))\n",
    "                with open(predictions_path, 'wb') as outfile:\n",
    "                    pickle.dump(p, outfile)\n",
    "                    \n",
    "            # oracle prediction\n",
    "            o = y[test_index[0]]\n",
    "            correct = p == o\n",
    "\n",
    "            # get runtime without thread coarsening\n",
    "            row = df[(df[\"kernel\"] == kernel) & (df[\"cf\"] == 1)]\n",
    "            assert(len(row) == 1)  # sanity check\n",
    "            nocf_runtime = float(row[\"runtime_\" + platform])\n",
    "\n",
    "            # get runtime of prediction\n",
    "            row = df[(df[\"kernel\"] == kernel) & (df[\"cf\"] == p)]\n",
    "            assert(len(row) == 1)  # sanity check\n",
    "            p_runtime = float(row[\"runtime_\" + platform])\n",
    "            \n",
    "            # get runtime of oracle coarsening factor\n",
    "            o_runtime = oracle_runtimes[test_index[0]]\n",
    "\n",
    "            # speedup and % oracle\n",
    "            s_oracle = nocf_runtime / o_runtime\n",
    "            p_speedup = nocf_runtime / p_runtime\n",
    "            p_oracle = o_runtime / p_runtime\n",
    "\n",
    "            # record result\n",
    "            data.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Platform\": platform_name,\n",
    "                \"Kernel\": kernel,\n",
    "                \"Oracle-CF\": o,\n",
    "                \"Predicted-CF\": p,\n",
    "                \"Speedup\": p_speedup,\n",
    "                \"Oracle\": p_oracle\n",
    "            })\n",
    "            \n",
    "            progressbar[0] += 1  # update progress bar\n",
    "            progressbar[1].update(progressbar[0])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\n",
    "        \"Model\", \"Platform\", \"Kernel\", \"Oracle-CF\", \"Predicted-CF\", \"Speedup\", \"Oracle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Magni et al. Model\n",
    "\n",
    "The Magni et al. predictive model.\n",
    "\n",
    "Described in publication:\n",
    "\n",
    "> [1] Magni, A., Dubach, C., & Oâ€™Boyle, M. (2014). [Automatic Optimization of Thread-Coarsening for Graphics Processors](http://www.research.ed.ac.uk/portal/files/19958629/magni14pact.pdf). In PACT. ACM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# during grid search, not all parameters will converge. Ignore these warnings\n",
    "from warnings import filterwarnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "class Magni(ThreadCoarseningModel):\n",
    "    __name__ = \"Magni et al.\"\n",
    "    __basename__ = \"magni\"\n",
    "\n",
    "    def init(self, seed: int=None):\n",
    "        # the neural network\n",
    "        nn = MLPClassifier(random_state=seed, shuffle=True)\n",
    "\n",
    "        # cross-validation over the training set. We train on 16 programs,\n",
    "        # so with k=16 and no shuffling of the data, we're performing\n",
    "        # nested leave-one-out cross-validation\n",
    "        inner_cv = KFold(n_splits=16, shuffle=False)\n",
    "\n",
    "        # hyper-parameter combinations to try\n",
    "        params = {\n",
    "            \"max_iter\": [200, 500, 1000, 2000],\n",
    "            \"hidden_layer_sizes\": [\n",
    "                (32,),\n",
    "                (32, 32),\n",
    "                (32, 32, 32),\n",
    "                (64,),\n",
    "                (64, 64),\n",
    "                (64, 64, 64),\n",
    "                (128,),\n",
    "                (128, 128),\n",
    "                (128, 128, 128),\n",
    "                (256,),\n",
    "                (256, 256),\n",
    "                (256, 256, 256),\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        self.model = GridSearchCV(nn, cv=inner_cv, param_grid=params, n_jobs=-1)\n",
    "\n",
    "    def save(self, outpath):\n",
    "        with open(outpath, 'wb') as outfile:\n",
    "            pickle.dump(self.model, outfile)\n",
    "\n",
    "    def restore(self, inpath):\n",
    "        with open(inpath, 'rb') as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "\n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        self.model.fit(cascading_features, cascading_y)\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        # we only support leave-one-out cross-validation (implementation detail):\n",
    "        assert(len(sequences) == 1)\n",
    "\n",
    "        # The binary cascading model:\n",
    "        #\n",
    "        # iteratively apply thread coarsening, using a new feature vector\n",
    "        # every time coarsening is applied\n",
    "        for i in range(len(cascading_features)):\n",
    "            # predict whether to coarsen, using the program features of\n",
    "            # the current coarsening level:\n",
    "            should_coarsen = self.model.predict([cascading_features[i]])[0]\n",
    "            if not should_coarsen:\n",
    "                break\n",
    "        p = cfs[i]\n",
    "        return [cfs[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating Magni et al. ...\", file=sys.stderr)\n",
    "magni = evaluate(Magni())\n",
    "magni.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. DeepTune\n",
    "\n",
    "We predict thread coarsening factor directly from raw source code inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepTune(ThreadCoarseningModel):\n",
    "    __name__ = \"DeepTune\"\n",
    "    __basename__ = \"deeptune\"\n",
    "\n",
    "    def init(self, seed: int=None):\n",
    "        from keras.layers import Input, Dropout, Embedding, merge, LSTM, Dense, Bidirectional\n",
    "        from keras.layers.normalization import BatchNormalization\n",
    "        from keras.models import Model, Sequential, load_model\n",
    "    \n",
    "        np.random.seed(seed)\n",
    "    \n",
    "        # Vocabulary has a padding character\n",
    "        vocab_size = atomizer.vocab_size + 1\n",
    "\n",
    "        # Language model. Takes as inputs source code sequences.\n",
    "        seq_inputs = Input(shape=(1024,), dtype=\"int32\")\n",
    "        x = Embedding(input_dim=vocab_size, input_length=1024,\n",
    "                      output_dim=64, name=\"embedding\")(seq_inputs)\n",
    "        x = Bidirectional(LSTM(64, return_sequences=True, implementation=1, name=\"lstm_1\"))(x)\n",
    "        x = Bidirectional(LSTM(64, implementation=1, name=\"lstm_2\"))(x)\n",
    "        \n",
    "        # Heuristic model. Takes as inputs the language model,\n",
    "        #   outputs 1-of-6 thread coarsening factor\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(32, activation=\"relu\")(x)\n",
    "        outputs = Dense(6, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.model = Model(inputs=seq_inputs, outputs=outputs)\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    def save(self, outpath: str):\n",
    "        self.model.save(outpath)\n",
    "\n",
    "    def restore(self, inpath: str):\n",
    "        self.model = load_model(inpath)\n",
    "        \n",
    "    def train(self, cascading_features: np.array, cascading_y: np.array,\n",
    "              sequences: np.array, y_1hot: np.array, verbose: bool=False) -> None:\n",
    "        self.model.fit(sequences, y_1hot, epochs=50, batch_size=64, verbose=verbose, shuffle=True)\n",
    "\n",
    "    def predict(self, cascading_features: np.array, sequences: np.array) -> np.array:\n",
    "        # directly predict optimal thread coarsening factor from source sequences:\n",
    "        p = np.array(self.model.predict(sequences, batch_size=64, verbose=0))\n",
    "        indices = [np.argmax(x) for x in p]\n",
    "        return [cfs[x] for x in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the DeepTune model, showing the number of parameters in each layer, used to construct Table 5 in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeptune_model = DeepTune()\n",
    "deeptune_model.init(seed)\n",
    "deeptune_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnotebook():\n",
    "    # written by @mtd http://stackoverflow.com/a/39662359\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':  # Jupyter notebook or qtconsole?\n",
    "            return True\n",
    "        elif shell == 'TerminalInteractiveShell':  # Terminal running IPython?\n",
    "            return False\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "\n",
    "img = None\n",
    "if isnotebook():\n",
    "    from keras.utils.vis_utils import model_to_dot\n",
    "    from IPython.display import SVG\n",
    "    img = SVG(model_to_dot(deeptune_model.model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating DeepTune ...\", file=sys.stderr)\n",
    "deeptune = evaluate(DeepTune())\n",
    "deeptune.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. DeepTune-TL\n",
    "\n",
    "As described in Section 4.3. of the paper, we use *Transfer Learning* to leverage information gained from one optimization problem for another. To do this, we simply initialize the language model with the weights learned for Case Study A. See '*Case Study A.ipynb*' for the code to produce these weights. Apart from initializing the weights from the other optimization task, the model remains unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepTune_TL(DeepTune):\n",
    "    __name__ = \"DeepTune-TL\"\n",
    "    __basename__ = \"deeptune_tl\"\n",
    "\n",
    "    starting_weights = \"../data/case-study-b/case-study-a-weights.h5\"\n",
    "\n",
    "    def init(self, *args, **kwargs):\n",
    "        super(DeepTune_TL, self).init(*args, **kwargs)\n",
    "        self.model.load_weights(self.starting_weights, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating DeepTune-TL ...\", file=sys.stderr)\n",
    "deeptune_tl = evaluate(DeepTune_TL())\n",
    "deeptune_tl.groupby('Platform')['Platform', 'Speedup', 'Oracle'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Average Speedup and Oracle of each model across all platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([\n",
    "    magni[['Speedup', 'Oracle']].mean(),\n",
    "    deeptune[['Speedup', 'Oracle']].mean(),\n",
    "    deeptune_tl[['Speedup', 'Oracle']].mean(),\n",
    "]).T\n",
    "\n",
    "pd.DataFrame(d, columns=[\"Magni et al.\", \"DeepTune\", \"DeepTune-TL\"], index=[\"Speedup\", \"Oracle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "### 4.1. Speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "d.append(np.append(magni.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   magni['Speedup'].mean()))\n",
    "d.append(np.append(deeptune.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   deeptune['Speedup'].mean()))\n",
    "d.append(np.append(deeptune_tl.groupby(['Platform'])['Speedup'].mean().values,\n",
    "                   deeptune_tl['Speedup'].mean()))\n",
    "d = np.array(d).T.reshape(5, 3)\n",
    "\n",
    "pd.DataFrame(d, columns=['Magni et al.', 'DeepTune', 'DeepTune-TL'],\n",
    "             index=['AMD Radeon HD 5900', 'AMD Tahiti 7970', \n",
    "                    'NVIDIA GTX 480', 'NVIDIA Tesla K20c', 'Average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 8 of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isnotebook():\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    from matplotlib.ticker import FormatStrFormatter\n",
    "    from labm8 import viz\n",
    "\n",
    "    # Plotting configuration\n",
    "    %matplotlib inline\n",
    "    sns.set(style=\"ticks\", color_codes=True)\n",
    "    plt.style.use([\"seaborn-white\", \"seaborn-paper\"])\n",
    "    matplotlib.rcParams['figure.dpi'] = 120\n",
    "\n",
    "    for i, platform in enumerate([\"AMD Radeon HD 5900\", \"AMD Tahiti 7970\", \"NVIDIA GTX 480\", \"NVIDIA Tesla K20c\"]):\n",
    "\n",
    "        def get_speedups(df, platform):\n",
    "            \"\"\" get % accuracies for platform, aggregated by benchmark suite \"\"\"\n",
    "            r = df[df[\"Platform\"] == platform]\n",
    "            d = pd.DataFrame(r[\"Speedup\"].values, columns=['Speedup'], index=r['Kernel'])\n",
    "            avg = pd.Series([d.mean(),], index=[\"Speedup\"], name=\"Average\")\n",
    "            return d.append(avg)\n",
    "\n",
    "        # Aggregate data\n",
    "        models, results = (Magni, DeepTune, DeepTune_TL), (magni, deeptune, deeptune_tl)\n",
    "        dfs = [get_speedups(r, platform) for r in results]\n",
    "\n",
    "        speedups    = np.concatenate([dfs[i]['Speedup'].values for i in range(len(dfs))])\n",
    "        kernels     = np.concatenate([dfs[i].index.values for i in range(len(dfs))])\n",
    "        model_names = np.concatenate([np.array([m().__name__] * len(dfs[0])) for m in models])\n",
    "\n",
    "        df = pd.DataFrame([{\"Kernel\": k, \"Speedup\": s - 1, \"Model\": m}\n",
    "                           for k, s, m in zip(kernels, speedups, model_names)])\n",
    "\n",
    "        # Plot\n",
    "        palette = sns.cubehelix_palette(3, rot=.5, light=.85, dark=.35)\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        ax = sns.barplot(x=\"Kernel\", y=\"Speedup\", hue=\"Model\", palette=palette, data=df)\n",
    "        plt.title(platform)\n",
    "\n",
    "        # y axis\n",
    "        plt.axhline(y=0, color=\"k\", lw=.5)\n",
    "        plt.ylim((-1, 1.5))\n",
    "        ax.set_yticklabels([\"{:.1f}x\".format(float(i) + 1.0) for i in ax.get_yticks()])  # negative offset\n",
    "        if i % 2:\n",
    "            plt.ylabel(\"\")  \n",
    "        else:\n",
    "            plt.ylabel(\"Speedup\")\n",
    "\n",
    "        # x axis\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90)  # rotate x ticks\n",
    "        plt.xlabel(\"\")\n",
    "        plt.axvline(x=plt.xlim()[1] - 1, color=\"k\", lw=1, linestyle=\"--\")  # average line\n",
    "\n",
    "        # legend\n",
    "        ax.get_legend().set_title(\"\")\n",
    "        plt.legend(loc='upper left', ncol=1)    \n",
    "        ax.get_legend().draw_frame(True)\n",
    "\n",
    "    viz.finalise(figsize=(9, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labm8 import math as labmath\n",
    "\n",
    "magni_geomean = labmath.geomean(magni['Speedup'].values)\n",
    "deeptune_geomean = labmath.geomean(deeptune['Speedup'].values)\n",
    "deeptune_tl_geomean = labmath.geomean(deeptune_tl['Speedup'].values)\n",
    "\n",
    "print(f\"Geometric mean of Magni et al. {magni_geomean:.2f}x\")\n",
    "print(f\"Geometric mean of DeepTune {deeptune_geomean:.2f}x\")\n",
    "print(f\"Geometric mean of DeepTune-TL {deeptune_tl_geomean:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Influence of Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_platform_speedups = deeptune.groupby(\"Platform\").mean()[\"Speedup\"].iteritems()\n",
    "dt_tl_platform_speedups = deeptune_tl.groupby(\"Platform\").mean()[\"Speedup\"].iteritems()\n",
    "\n",
    "num_improvements = 0\n",
    "tl_speedups = []\n",
    "for (platform, speedup), (_, speedup_tl) in zip(dt_platform_speedups, dt_tl_platform_speedups):\n",
    "    if speedup_tl > speedup:\n",
    "        num_improvements += 1\n",
    "    tl_speedup = (speedup_tl / speedup) - 1\n",
    "    tl_speedups.append({\"Platform\": platform, \"TL-speedup\": tl_speedup})\n",
    "\n",
    "max_tl_speedup = max(tl_speedups, key=lambda x: x[\"TL-speedup\"])\n",
    "print(f\"Transfer Learning improved performance on {num_improvements} of the 4 platforms\")\n",
    "print(\"The greatest per-platform performance improvement was \"\n",
    "      f\"{max_tl_speedup['TL-speedup']:.1%} on {max_tl_speedup['Platform']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Comparison to State-of-the-art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeptune_speedup = deeptune[\"Speedup\"].mean()\n",
    "deeptune_tl_speedup = deeptune_tl[\"Speedup\"].mean()\n",
    "magni_speedup = magni[\"Speedup\"].mean()\n",
    "\n",
    "performance_improvement = (deeptune_speedup / magni_speedup) - 1\n",
    "performance_improvement_tl = (deeptune_tl_speedup / magni_speedup) - 1\n",
    "\n",
    "print(f\"DeepTune outperforms state-of-the-art by {performance_improvement:.0%}\")\n",
    "print(f\"DeepTune-TL outperforms state-of-the-art by {performance_improvement_tl:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases = len(deeptune_tl)\n",
    "num_better = sum(1 for d, m in zip(deeptune_tl[\"Speedup\"], magni[\"Speedup\"]) if d >= m)\n",
    "ratio_better = num_better / num_cases\n",
    "print(\"DeepTune-TL matched or improved performance of state-of-the-art in \"\n",
    "      f\"{num_better} of {num_cases} cases ({ratio_better:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2e-dl",
   "language": "python",
   "name": "e2e-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
